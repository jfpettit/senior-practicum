{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Temporal Difference Learning\n",
    "\n",
    "Is a combo of MC and DP ideas. Like MC, TD can learn from raw experience w/ no knowledge of environment dynamics. Like DP, TD methods bootstrap by using other learned estimates to update new estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 TD Prediction\n",
    "\n",
    "TD and MC use experience to solve the prediction problem. MC methods wait until the return following an episode is known and then use the return to estimate a target for $V(S_t)$, where $V$ is value of a particular state in $v_\\pi$. Here's a simple every-visit MC method for nonstationary problems:\n",
    "\n",
    "$V(S_t) \\leftarrow V(S_t) + \\alpha [G_t - V(S-t)] \\quad (6.1)$\n",
    "\n",
    "$\\alpha$ is a constant step-size parameter and $G_t$ is actual return following time $t$. Name this method $constant-\\alpha$ MC. \n",
    "\n",
    "Where MC methods have to wait until the return is known at the end of an episode to update $V(S_t)$, TD methods only need to wait until the next timestep. At $t+1$ time they'll immediately form a target value and make an update using the observed reward $R_{t+1}$ and the existing value estimate $V(S_{t+1}$. Simplest TD method goes:\n",
    "\n",
    "$V(S_t) \\leftarrow V(S_t) + \\alpha[R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)] \\quad (6.2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called $TD(0)$ or $one-step TD$. \n",
    "\n",
    "Algo for TD(0):\n",
    "\n",
    "Input: $\\pi$  \n",
    "Parameter: $\\alpha \\in (0, 1]$  \n",
    "Start $V(s)$ for all $s \\in S^+$, arbitrarily except $V(terminal) = 0$\n",
    "\n",
    "Loop for each episode:  \n",
    "    $\\quad$Initialize S  \n",
    "    $\\quad$Loop for each step of episode:  \n",
    "        $\\quad$$\\quad$$A \\leftarrow$ action given from $\\pi$ for $S$  \n",
    "        $\\quad$$\\quad$Take action $A$, observe $R, S'$  \n",
    "        $\\quad$$\\quad$$V(S) \\leftarrow V(S) + \\alpha[R + \\gamma V(S') - V(S)]$  \n",
    "        $\\quad$$\\quad$$S\\leftarrow S'$  \n",
    "    $\\quad$ Until $S$ is terminal.\n",
    "    \n",
    "\n",
    "Since TD(0) bases its update partially on an existing estimate, we call it a *bootstrapping* method.\n",
    "\n",
    "From Chapter 3:\n",
    "\n",
    "$v_\\pi(s) \\stackrel{.}{=} \\mathbb{E}_\\pi[G_t | S_t = s] \\quad (6.3)$  \n",
    "$v_\\pi(s) = \\mathbb{E}_\\pi [R_{t+1} + \\gamma G_{t+1} | S_t = s] \\quad(by (3.9))$  \n",
    "$v_\\pi(s) = \\mathbb{E}_\\pi [R_{t+1} + \\gamma v_\\pi(S_{t+1}) | S_t = s]\\quad (6.4)$  \n",
    "\n",
    "MC methods use estimate of (6.3) as a target, DP use estimate of (6.4) as a target. MC target is an estimate because the real return isn't known, a sample estimate is used in it's place. DP is an estimate because $v_\\pi(S_{t+1})$ isn't known and instead an estimate $V(S_{t+1})$ is used. TD is an estimate for both of these reasons, it both samples the expected values in (6.4) and uses estimate $V$ instead of real $v_\\pi$. So TD combines sampling of MC with bootstrapping of DP. \n",
    "\n",
    "We refer to TD and MC updates as *sample updates* because they involve looking ahead to a sample state, or state-action pair, using the successor and the reward along the way to compute a backed up value and then updating the value of the original state accordingly. **\"Sample updates differ from the expected updates in DP methods in that they are based on a single sample successor rather than on a complete distribution of all possible successors.\"\n",
    "\n",
    "Observe that the piece of TD(0) in brackets is kind of an error. It measures difference between estimated value of $S_t$ and the superior estimate $R_{t+1} + \\gamma V(S_{t+1})$. This is called the TD error and arises in diff. forms throughout RL:\n",
    "\n",
    "$\\delta_t \\stackrel{.}{=} R_{t+1} + \\gamma V(S_{t+1}) - V(S_t) \\quad (6.5)$\n",
    "\n",
    "TD error at each time step is the error in the estimate at that time. Since the TD error depends on the next state and next reward, it isn't available until one time step later. \n",
    "\n",
    "If $V$ doesn't change during episodes (like it doesn't during MC methods), then MC error can be written as a sum of TD errors:\n",
    "\n",
    "$G_t - V(S_t) = R_{t+1} + \\gamma G_{t+1} - V(S_t) + \\gamma V(S_{t+1}) - \\gamma V(S_{t+1})$  \n",
    "$G_t - V(S_t) = \\delta_t + \\gamma(G_{t+1} - V(S_{t+1}))$  \n",
    "$G_t - V(S_t) = \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 (G_{t+2} - V(S_{t+2}))$  \n",
    "$G_t - V(S_t) = \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} \\dotsb + \\gamma^{T-t+1}\\delta{T-1} + \\gamma^{T-t}(G_T - V(S_T))$  \n",
    "$G_t - V(S_t) = \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2 \\delta_{t+2} \\dotsb + \\gamma^{T-t+1}\\delta{T-1} + \\gamma^{T-t}(0 - 0)$  \n",
    "$G_t - V(S_t) = \\sum_{k=t}^{T-1} \\gamma^{k-t}\\delta_t$\n",
    "\n",
    "This identity is not perfectly exact if the $V$ is updated during the episode like in TD(0), but if step size is sufficiently small then it may hold approximately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Advantages of TD Prediction Methods\n",
    "\n",
    "TD methods bootstrap, aka they update their estimates based partially on other estimates.\n",
    "\n",
    "They also have advantage over DP since they don't require a model of the environment. Their advantage over MC is that they're fully implemented in an online fashion. MC has to wait unitl the end of the episode to make updates to value estimations while TD has to wait only one time step. Often this is a big deal. Sometimes the task has an extremely long episode, so we can't deal with delaying all learning until ends of episodes because it is too slow. Alternatively, the task could be continuing and have no episodes at all. MC has to ignore or discount experimental actions, so that can slow learning a lot. TD, on the other hand, can learn from all state transitions regardless of which actions are taken.\n",
    "\n",
    "TD(0) has also been shown to converge to $v_\\pi$ in the average of a constant $\\alpha$ if it is small enough. and with probability 1 if the step-size decreases according to usual stochastic approximation conditions (2.7). In practice, TD methods usually converge faster than $constant-\\alpha$ MC methods on stochastic tasks. \n",
    "\n",
    "MCs optimality is limited, TD is optimal in a way more relevant to predicting returns than MC is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Sarsa: On Policy TD Control\n",
    "\n",
    "Follow GPI again for turning to TD control problem. We use TD for the evaluation part this time. \n",
    "\n",
    "Start with learning action-value function. For an on-policy method we need to estimate $q_\\pi(s,a)$ for current policy $\\pi$ and all actions $a$ and states $s$. This can be done using the method above for learning state-value function. Recall an episode is made up of alternating sequence of states and state-action pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='screenshot_6.4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we were looking at transitions from state to state and learned state-values. Now we are looking at transitions from state-action pair to state-action pair and learning state-action pair values. These cases are identical because they are both Markov chains with reward processes. The theorems that guarantee convergence of state-values under TD(0) also apply to the corresponding algorithm for action values:\n",
    "\n",
    "$Q(S_t,A_t) \\leftarrow Q(S_t, A_t) + \\alpha [R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t)] \\quad (6.7)$\n",
    "\n",
    "This is done after every transition from a nonterminal state. If the state is terminal then $Q(S_{t+1}, A_{t+1})$ is equal to zero. This rule uses every element of the following quintuple of elements: $(S_t, A_t, R_{t+1}, S_{t+1}, A_{t+1})$. This quintuple gives rise to the name SARSA. It is simple to design an on-policy control algorithm based on Sarsa. Like in all on-policy methods, we continuously estimate $q_\\pi$ for $\\pi$ and at the same time make $\\pi$ greedy with respect to $q_\\pi$. \n",
    "\n",
    "Sarsa's convergence depends on the nature of the policy's dependence on $q$. One could use $\\varepsilon$-greedy or $\\varepsilon$-soft policies. Sarsa converges with guaranteed chance to an optimal policy and action-value function as long as all state-aciton pairs are visited an infinite number of times and the policy converges in the limit to the greedy policy. This can be arranged by setting $\\varepsilon = 1/t$.\n",
    "\n",
    "Algorithm for Sarsa:\n",
    "\n",
    "Parameters: stepsize $\\alpha \\in (0, 1]$, small $\\varepsilon > 0$\n",
    "Initialize $Q(s,a)$ for all $s \\in S^+, a \\in A(s)$, arbitrarily except $Q(terminal, -) =0$\n",
    "\n",
    "Loop for each episode:  \n",
    "$\\quad$Initialize $S$.  \n",
    "$\\quad$Pick $A$ from $S$ using the policy derived from $Q$  \n",
    "$\\quad$Loop for each step of the episode:  \n",
    "$\\quad$$\\quad$Pick action $A$, observe $R, S'$  \n",
    "$\\quad$$\\quad$Choose $A'$ from $S'$, using policy derived from $Q$  \n",
    "$\\quad$$\\quad$$Q(S,A) \\leftarrow Q(S, A) + \\alpha[[R_{t+1} + \\gamma Q(S', A') - Q(S, A)]$  \n",
    "$\\quad$$\\quad$$S\\leftarrow S', A \\leftarrow A'$  \n",
    "$\\quad$Until $S$ is terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01883447 0.03221454 0.04018006 0.02065956]\n",
      "[ 0.01947876  0.22673792  0.04059325 -0.25908025]\n",
      "[ 0.02401352  0.42125757  0.03541164 -0.53868821]\n",
      "[ 0.03243867  0.61586426  0.02463788 -0.8200064 ]\n",
      "[ 0.04475596  0.81064052  0.00823775 -1.10483932]\n",
      "[ 0.06096877  1.00565318 -0.01385904 -1.39492651]\n",
      "[ 0.08108183  0.81070639 -0.04175757 -1.10660883]\n",
      "[ 0.09729596  0.61615754 -0.06388974 -0.82731311]\n",
      "[ 0.10961911  0.42196466 -0.080436   -0.5553889 ]\n",
      "[ 0.11805841  0.22805873 -0.09154378 -0.28909311]\n",
      "[ 0.12261958  0.42435875 -0.09732564 -0.6091865 ]\n",
      "[ 0.13110675  0.23072239 -0.10950937 -0.34867511]\n",
      "[ 0.1357212   0.03731451 -0.11648288 -0.09243255]\n",
      "[ 0.13646749 -0.15596192 -0.11833153  0.16134894]\n",
      "[ 0.13334825  0.04063779 -0.11510455 -0.16619673]\n",
      "[ 0.13416101  0.23720315 -0.11842848 -0.49285976]\n",
      "[ 0.13890507  0.43377891 -0.12828568 -0.82039468]\n",
      "[ 0.14758065  0.24062396 -0.14469357 -0.57065571]\n",
      "[ 0.15239313  0.04779582 -0.15610669 -0.32682766]\n",
      "[ 0.15334905  0.24475581 -0.16264324 -0.66438431]\n",
      "[ 0.15824416  0.44172176 -0.17593093 -1.00354069]\n",
      "[ 0.1670786   0.24933045 -0.19600174 -0.77086563]\n",
      "Episode finished after 22 timesteps\n",
      "[-0.00495124  0.00371407 -0.01345086  0.01979702]\n",
      "[-0.00487696  0.19902631 -0.01305492 -0.27709927]\n",
      "[-0.00089643  0.00409302 -0.0185969   0.01143772]\n",
      "[-0.00081457 -0.19075736 -0.01836815  0.29819557]\n",
      "[-0.00462972  0.00462154 -0.01240424 -0.00022328]\n",
      "[-0.00453729 -0.19032034 -0.0124087   0.28852029]\n",
      "[-0.0083437  -0.38526316 -0.0066383   0.57726395]\n",
      "[-0.01604896 -0.19004879  0.00490698  0.28249721]\n",
      "[-0.01984994  0.00500282  0.01055693 -0.00863404]\n",
      "[-0.01974988 -0.19026893  0.01038425  0.28736094]\n",
      "[-0.02355526  0.00470341  0.01613146 -0.00202889]\n",
      "[-0.02346119  0.19959034  0.01609089 -0.2895788 ]\n",
      "[-0.01946938  0.39447919  0.01029931 -0.57714372]\n",
      "[-0.0115798   0.1992144  -0.00124356 -0.28123413]\n",
      "[-0.00759551  0.00411021 -0.00686825  0.01105632]\n",
      "[-0.00751331  0.19932999 -0.00664712 -0.28378568]\n",
      "[-0.00352671  0.00430347 -0.01232283  0.00679339]\n",
      "[-0.00344064  0.19959996 -0.01218697 -0.28975192]\n",
      "[ 0.00055136  0.00465389 -0.017982   -0.00093741]\n",
      "[ 0.00064444 -0.19020562 -0.01800075  0.28601817]\n",
      "[-0.00315967 -0.38506628 -0.01228039  0.57296988]\n",
      "[-1.08609977e-02 -5.80013915e-01 -8.20990511e-04  8.61758940e-01]\n",
      "[-0.02246128 -0.38488079  0.01641419  0.56881799]\n",
      "[-0.03015889 -0.18999287  0.02779055  0.28135103]\n",
      "[-0.03395875  0.00472188  0.03341757 -0.00243894]\n",
      "[-0.03386431  0.19934903  0.03336879 -0.28439374]\n",
      "[-0.02987733  0.39397956  0.02768091 -0.56636841]\n",
      "[-0.02199774  0.58870248  0.01635355 -0.85020374]\n",
      "[-1.02236901e-02  7.83597658e-01 -6.50528162e-04 -1.13769969e+00]\n",
      "[ 0.00544826  0.97872811 -0.02340452 -1.43058656]\n",
      "[ 0.02502283  1.17413104 -0.05201625 -1.73049098]\n",
      "[ 0.04850545  1.36980703 -0.08662607 -2.03889386]\n",
      "[ 0.07590159  1.17567665 -0.12740395 -1.77422641]\n",
      "[ 0.09941512  1.37198395 -0.16288848 -2.10365629]\n",
      "[ 0.1268548   1.56832289 -0.2049616  -2.441944  ]\n",
      "Episode finished after 35 timesteps\n",
      "[-0.02402169 -0.04005025 -0.01008289  0.01230813]\n",
      "[-0.02482269 -0.23502616 -0.00983673  0.30179281]\n",
      "[-0.02952321 -0.43000654 -0.00380087  0.59135728]\n",
      "[-0.03812334 -0.62507507  0.00802628  0.88284051]\n",
      "[-0.05062485 -0.43006304  0.02568309  0.59269158]\n",
      "[-0.05922611 -0.62553493  0.03753692  0.89335272]\n",
      "[-0.07173681 -0.43094164  0.05540397  0.61270166]\n",
      "[-0.08035564 -0.23663595  0.067658    0.33797078]\n",
      "[-0.08508836 -0.04253874  0.07441742  0.06736736]\n",
      "[-0.08593913  0.15144176  0.07576477 -0.20093954]\n",
      "[-0.0829103   0.34540296  0.07174598 -0.46879315]\n",
      "[-0.07600224  0.14934468  0.06237011 -0.15438709]\n",
      "[-0.07301534 -0.04661228  0.05928237  0.15730175]\n",
      "[-0.07394759  0.14761301  0.06242841 -0.11610558]\n",
      "[-0.07099533  0.34178749  0.0601063  -0.38845788]\n",
      "[-0.06415958  0.14586618  0.05233714 -0.077446  ]\n",
      "[-0.06124226  0.3402003   0.05078822 -0.35316794]\n",
      "[-0.05443825  0.53456465  0.04372486 -0.62941322]\n",
      "[-0.04374696  0.33886067  0.03113659 -0.32328682]\n",
      "[-0.03696974  0.14330951  0.02467086 -0.02094957]\n",
      "[-0.03410355 -0.0521574   0.02425187  0.27941407]\n",
      "[-0.0351467  -0.24761677  0.02984015  0.57964625]\n",
      "[-0.04009904 -0.4431439   0.04143307  0.88157809]\n",
      "[-0.04896191 -0.63880341  0.05906464  1.18699331]\n",
      "[-0.06173798 -0.44449497  0.0828045   0.91339381]\n",
      "[-0.07062788 -0.64063354  0.10107238  1.23091032]\n",
      "[-0.08344055 -0.44694639  0.12569058  0.97152703]\n",
      "[-0.09237948 -0.64351054  0.14512112  1.30090312]\n",
      "[-0.10524969 -0.45049733  0.17113919  1.05694263]\n",
      "[-0.11425964 -0.25800502  0.19227804  0.8224919 ]\n",
      "[-0.11941974 -0.06596018  0.20872788  0.59591536]\n",
      "Episode finished after 31 timesteps\n",
      "[ 0.01463175  0.02007558 -0.01457163  0.00970794]\n",
      "[ 0.01503326 -0.17483439 -0.01437747  0.29775796]\n",
      "[ 0.01153658  0.02048953 -0.00842231  0.00057553]\n",
      "[ 0.01194637  0.21573125 -0.0084108  -0.29475279]\n",
      "[ 0.01626099  0.02073021 -0.01430586 -0.00473433]\n",
      "[ 0.0166756   0.21605437 -0.01440055 -0.30189638]\n",
      "[ 0.02099668  0.41137858 -0.02043847 -0.59908592]\n",
      "[ 0.02922426  0.60678044 -0.03242019 -0.89813598]\n",
      "[ 0.04135986  0.41211257 -0.05038291 -0.61581749]\n",
      "[ 0.04960212  0.2177294  -0.06269926 -0.33941904]\n",
      "[ 0.0539567   0.02355303 -0.06948764 -0.06714832]\n",
      "[ 0.05442776  0.21959888 -0.07083061 -0.38092034]\n",
      "[ 0.05881974  0.41565138 -0.07844902 -0.6950685 ]\n",
      "[ 0.06713277  0.22170011 -0.09235039 -0.42807672]\n",
      "[ 0.07156677  0.02799913 -0.10091192 -0.1658758 ]\n",
      "[ 0.07212675 -0.16554438 -0.10422944  0.09334477]\n",
      "[ 0.06881587 -0.35902997 -0.10236254  0.35141009]\n",
      "[ 0.06163527 -0.55255858 -0.09533434  0.61014141]\n",
      "[ 0.0505841  -0.35624239 -0.08313151  0.28901845]\n",
      "[ 0.04345925 -0.55008657 -0.07735114  0.55436806]\n",
      "[ 0.03245752 -0.74404204 -0.06626378  0.82171277]\n",
      "[ 0.01757668 -0.93819778 -0.04982952  1.09283993]\n",
      "[-1.18728002e-03 -1.13262903e+00 -2.79727260e-02  1.36948098e+00]\n",
      "[-2.38398606e-02 -1.32739005e+00 -5.83106327e-04  1.65328531e+00]\n",
      "[-0.05038766 -1.52250519  0.0324826   1.94578654]\n",
      "[-0.08083777 -1.71795761  0.07139833  2.24835873]\n",
      "[-0.11519692 -1.91367534  0.11636551  2.56216063]\n",
      "[-0.15347042 -2.10951437  0.16760872  2.88806683]\n",
      "Episode finished after 28 timesteps\n",
      "[0.03060063 0.00888451 0.034307   0.04725694]\n",
      "[ 0.03077832 -0.18671215  0.03525214  0.35056357]\n",
      "[0.02704408 0.00789119 0.04226341 0.0692019 ]\n",
      "[ 0.02720191  0.20238254  0.04364745 -0.20985286]\n",
      "[ 0.03124956  0.3968541   0.03945039 -0.48845411]\n",
      "[ 0.03918664  0.20119841  0.02968131 -0.18360352]\n",
      "[ 0.04321061  0.39588336  0.02600924 -0.4667773 ]\n",
      "[ 0.05112827  0.20040377  0.01667369 -0.16601123]\n",
      "[ 0.05513635  0.39528313  0.01335347 -0.4533878 ]\n",
      "[ 0.06304201  0.59021373  0.00428571 -0.74183182]\n",
      "[ 0.07484629  0.39503288 -0.01055093 -0.44780324]\n",
      "[ 0.08274694  0.59030248 -0.01950699 -0.74379325]\n",
      "[ 0.09455299  0.78568815 -0.03438286 -1.04255069]\n",
      "[ 0.11026676  0.59103929 -0.05523387 -0.76085654]\n",
      "[ 0.12208754  0.39672002 -0.070451   -0.48605263]\n",
      "[ 0.13002194  0.59276169 -0.08017205 -0.80008115]\n",
      "[ 0.14187718  0.39882561 -0.09617368 -0.53365676]\n",
      "[ 0.14985369  0.59515919 -0.10684681 -0.85502771]\n",
      "[ 0.16175687  0.79156235 -0.12394737 -1.17930563]\n",
      "[ 0.17758812  0.59824828 -0.14753348 -0.92790638]\n",
      "[ 0.18955308  0.40539306 -0.16609161 -0.68498378]\n",
      "[ 0.19766095  0.60238377 -0.17979128 -1.02501024]\n",
      "[ 0.20970862  0.79938473 -0.20029149 -1.36832283]\n",
      "Episode finished after 23 timesteps\n",
      "[-0.02770197 -0.0461272  -0.00379331 -0.01264445]\n",
      "[-0.02862452 -0.24119455 -0.0040462   0.27883923]\n",
      "[-0.03344841 -0.43625854  0.00153058  0.57024325]\n",
      "[-0.04217358 -0.63140193  0.01293545  0.86340798]\n",
      "[-0.05480162 -0.82669757  0.03020361  1.16012985]\n",
      "[-0.07133557 -1.02219973  0.05340621  1.46212784]\n",
      "[-0.09177956 -1.217934    0.08264876  1.7710046 ]\n",
      "[-0.11613824 -1.41388553  0.11806886  2.08819968]\n",
      "[-0.14441595 -1.22013675  0.15983285  1.83423149]\n",
      "[-0.16881869 -1.41662554  0.19651748  2.171999  ]\n",
      "Episode finished after 10 timesteps\n",
      "[-0.04851046 -0.009909    0.0378435  -0.03904015]\n",
      "[-0.04870864 -0.20555261  0.03706269  0.26533849]\n",
      "[-0.05281969 -0.40118341  0.04236946  0.56947711]\n",
      "[-0.06084336 -0.20668051  0.05375901  0.29043748]\n",
      "[-0.06497697 -0.40252616  0.05956775  0.5995791 ]\n",
      "[-0.07302749 -0.20828597  0.07155934  0.32623814]\n",
      "[-0.07719321 -0.40434993  0.0780841   0.6406019 ]\n",
      "[-0.08528021 -0.21039839  0.09089614  0.37349446]\n",
      "[-0.08948818 -0.40668606  0.09836603  0.69339717]\n",
      "[-0.0976219  -0.21305632  0.11223397  0.43322958]\n",
      "[-0.10188303 -0.40957351  0.12089856  0.75907831]\n",
      "[-0.1100745  -0.60613548  0.13608013  1.08722676]\n",
      "[-0.12219721 -0.41304469  0.15782466  0.84015234]\n",
      "[-0.1304581  -0.60992858  0.17462771  1.17801578]\n",
      "[-0.14265667 -0.8068342   0.19818803  1.5199622 ]\n",
      "Episode finished after 15 timesteps\n",
      "[ 0.02989599  0.03281507 -0.03276043  0.0488591 ]\n",
      "[ 0.03055229  0.22839109 -0.03178325 -0.25397736]\n",
      "[ 0.03512011  0.4239521  -0.0368628  -0.55651344]\n",
      "[ 0.04359915  0.61957166 -0.04799307 -0.86057864]\n",
      "[ 0.05599058  0.42513503 -0.06520464 -0.58336406]\n",
      "[ 0.06449328  0.62110695 -0.07687192 -0.89585384]\n",
      "[ 0.07691542  0.81718227 -0.094789   -1.21167635]\n",
      "[ 0.09325907  0.62340305 -0.11902253 -0.95013862]\n",
      "[ 0.10572713  0.81990857 -0.1380253  -1.27772161]\n",
      "[ 0.1221253   1.01649352 -0.16357973 -1.61024535]\n",
      "[ 0.14245517  0.8236382  -0.19578464 -1.37270236]\n",
      "Episode finished after 11 timesteps\n",
      "[ 0.03990562  0.00628077  0.03996217 -0.04113304]\n",
      "[ 0.04003123 -0.18939077  0.03913951  0.26388569]\n",
      "[ 0.03624342 -0.38504889  0.04441722  0.56865218]\n",
      "[ 0.02854244 -0.58076477  0.05579027  0.87499082]\n",
      "[ 0.01692714 -0.38644383  0.07329008  0.60035675]\n",
      "[ 0.00919827 -0.19241958  0.08529722  0.33162967]\n",
      "[0.00534988 0.00139122 0.09192981 0.06701738]\n",
      "[ 0.0053777  -0.19492027  0.09327016  0.38723051]\n",
      "[ 0.0014793  -0.39123388  0.10101477  0.7078027 ]\n",
      "[-0.00634538 -0.58759929  0.11517082  1.03049718]\n",
      "[-0.01809737 -0.39418233  0.13578077  0.77607918]\n",
      "[-0.02598101 -0.20116308  0.15130235  0.52901213]\n",
      "[-0.03000428 -0.39805352  0.16188259  0.86528713]\n",
      "[-0.03796535 -0.59496473  0.17918833  1.20417808]\n",
      "[-0.04986464 -0.40255304  0.2032719   0.9725816 ]\n",
      "Episode finished after 15 timesteps\n",
      "[-0.03519529 -0.04171315  0.01102379 -0.01958932]\n",
      "[-0.03602956 -0.23699144  0.01063201  0.27655125]\n",
      "[-0.04076939 -0.43226345  0.01616303  0.57256846]\n",
      "[-0.04941465 -0.62760826  0.0276144   0.87029913]\n",
      "[-0.06196682 -0.4328726   0.04502038  0.5864246 ]\n",
      "[-0.07062427 -0.62859523  0.05674887  0.89294259]\n",
      "[-0.08319618 -0.43428701  0.07460773  0.61862467]\n",
      "[-0.09188192 -0.63036744  0.08698022  0.93384144]\n",
      "[-0.10448927 -0.43651976  0.10565705  0.6697091 ]\n",
      "[-0.11321966 -0.24301316  0.11905123  0.41207325]\n",
      "[-0.11807992 -0.04976228  0.1272927   0.15916719]\n",
      "[-0.11907517 -0.24645506  0.13047604  0.48914232]\n",
      "[-0.12400427 -0.44315306  0.14025889  0.81993266]\n",
      "[-0.13286733 -0.25020059  0.15665754  0.57444722]\n",
      "[-0.13787134 -0.0575816   0.16814648  0.33492604]\n",
      "[-0.13902298  0.13479815  0.174845    0.09962867]\n",
      "[-0.13632701  0.32703939  0.17683758 -0.13319377]\n",
      "[-0.12978622  0.51924558  0.1741737  -0.36528716]\n",
      "[-0.11940131  0.32213163  0.16686796 -0.02314116]\n",
      "[-0.11295868  0.51451637  0.16640514 -0.25887806]\n",
      "[-0.10266835  0.31745817  0.16122757  0.08132382]\n",
      "[-0.09631919  0.50994582  0.16285405 -0.15646728]\n",
      "[-0.08612027  0.70240696  0.15972471 -0.39367145]\n",
      "[-0.07207213  0.50542173  0.15185128 -0.05519506]\n",
      "[-0.0619637   0.69807712  0.15074738 -0.29637985]\n",
      "[-0.04800216  0.50116366  0.14481978  0.03979265]\n",
      "[-0.03797888  0.69394405  0.14561563 -0.20392253]\n",
      "[-0.0241      0.49707233  0.14153718  0.13091959]\n",
      "[-0.01415856  0.68991301  0.14415557 -0.11397577]\n",
      "[-3.60296407e-04  4.93051267e-01  1.41876057e-01  2.20489044e-01]\n",
      "[0.00950073 0.29621647 0.14628584 0.55434645]\n",
      "[0.01542506 0.0993761  0.15737277 0.88930823]\n",
      "[ 0.01741258 -0.09749099  0.17515893  1.22703651]\n",
      "[ 0.01546276 -0.29438043  0.19969966  1.56908553]\n",
      "Episode finished after 34 timesteps\n",
      "[-0.01997818  0.04942333  0.00287351  0.00560804]\n",
      "[-0.01898971  0.24450396  0.00298567 -0.28616688]\n",
      "[-0.01409963  0.04933955 -0.00273767  0.00745621]\n",
      "[-0.01311284  0.24450066 -0.00258854 -0.28608923]\n",
      "[-0.00822283  0.04941572 -0.00831033  0.00577617]\n",
      "[-0.00723451  0.24465586 -0.00819481 -0.28951714]\n",
      "[-0.00234139  0.4398937  -0.01398515 -0.58477331]\n",
      "[ 0.00645648  0.24497042 -0.02568061 -0.29652847]\n",
      "[ 0.01135589  0.44044887 -0.03161118 -0.59719874]\n",
      "[ 0.02016487  0.63599858 -0.04355516 -0.89966891]\n",
      "[ 0.03288484  0.83168286 -0.06154854 -1.20571812]\n",
      "[ 0.04951849  0.63740792 -0.0856629  -0.93294135]\n",
      "[ 0.06226665  0.83357467 -0.10432173 -1.25126662]\n",
      "[ 0.07893815  0.6399326  -0.12934706 -0.99299762]\n",
      "[ 0.0917368   0.44675614 -0.14920701 -0.74357562]\n",
      "[ 0.10067192  0.64358787 -0.16407852 -1.07924707]\n",
      "[ 0.11354368  0.45096747 -0.18566347 -0.84221994]\n",
      "[ 0.12256303  0.64807212 -0.20250786 -1.18706776]\n",
      "Episode finished after 18 timesteps\n",
      "[-0.03260687  0.00246229 -0.04428341 -0.02645424]\n",
      "[-0.03255762 -0.19199754 -0.0448125   0.25193449]\n",
      "[-0.03639758 -0.3864519  -0.03977381  0.53015274]\n",
      "[-0.04412661 -0.58099243 -0.02917075  0.81004234]\n",
      "[-0.05574646 -0.77570282 -0.0129699   1.09340868]\n",
      "[-0.07126052 -0.97065152  0.00889827  1.38199408]\n",
      "[-0.09067355 -0.77564172  0.03653815  1.09210702]\n",
      "[-0.10618638 -0.97122561  0.05838029  1.39602688]\n",
      "[-0.1256109  -1.16702321  0.08630083  1.70637697]\n",
      "[-0.14895136 -0.97299343  0.12042837  1.44175642]\n",
      "[-0.16841123 -0.77954261  0.1492635   1.18900228]\n",
      "[-0.18400208 -0.5866367   0.17304354  0.94658153]\n",
      "[-0.19573481 -0.3942141   0.19197517  0.71287958]\n",
      "[-0.2036191  -0.59140226  0.20623276  1.05932274]\n",
      "Episode finished after 14 timesteps\n",
      "[-0.00865085 -0.04563598  0.03198268 -0.00647223]\n",
      "[-0.00956357  0.14901304  0.03185324 -0.28889514]\n",
      "[-0.00658331 -0.04654831  0.02607533  0.01366136]\n",
      "[-0.00751428 -0.24203432  0.02634856  0.31445598]\n",
      "[-0.01235496 -0.04729742  0.03263768  0.0301976 ]\n",
      "[-0.01330091  0.14734165  0.03324163 -0.25201176]\n",
      "[-0.01035408 -0.04823882  0.0282014   0.05096811]\n",
      "[-0.01131885 -0.24375356  0.02922076  0.35241372]\n",
      "[-0.01619392 -0.43927858  0.03626903  0.65416574]\n",
      "[-0.0249795  -0.63488627  0.04935235  0.95804507]\n",
      "[-0.03767722 -0.4404614   0.06851325  0.68126656]\n",
      "[-0.04648645 -0.24635453  0.08213858  0.41091648]\n",
      "[-0.05141354 -0.05248725  0.09035691  0.14521759]\n",
      "[-0.05246329 -0.24877921  0.09326126  0.46498319]\n",
      "[-0.05743887 -0.05509028  0.10256093  0.20309145]\n",
      "[-0.05854068 -0.25151804  0.10662276  0.52628489]\n",
      "[-0.06357104 -0.447966    0.11714845  0.85057118]\n",
      "[-0.07253036 -0.64447378  0.13415988  1.17767546]\n",
      "[-0.08541983 -0.45132474  0.15771339  0.92988013]\n",
      "[-0.09444633 -0.64818339  0.17631099  1.26767904]\n",
      "[-0.10740999 -0.45569623  0.20166457  1.03499166]\n",
      "Episode finished after 21 timesteps\n",
      "[-0.02279069 -0.00234465 -0.04466452  0.01592299]\n",
      "[-0.02283758 -0.19679854 -0.04434606  0.29418593]\n",
      "[-0.02677355 -0.39126112 -0.03846234  0.57255956]\n",
      "[-0.03459878 -0.19562157 -0.02701115  0.26801213]\n",
      "[-0.03851121 -0.39034783 -0.0216509   0.55205466]\n",
      "[-0.04631817 -0.19492861 -0.01060981  0.25262967]\n",
      "[-0.05021674  0.00034322 -0.00555722 -0.04338082]\n",
      "[-0.05020987  0.19554442 -0.00642483 -0.33781191]\n",
      "[-0.04629898  0.00051448 -0.01318107 -0.04716193]\n",
      "[-0.04628869  0.19582293 -0.01412431 -0.34397428]\n",
      "[-0.04237224  0.39114294 -0.0210038  -0.64107748]\n",
      "[-0.03454938  0.5865513  -0.03382535 -0.94030003]\n",
      "[-0.02281835  0.78211245 -0.05263135 -1.24341671]\n",
      "[-0.0071761   0.58770393 -0.07749968 -0.9676742 ]\n",
      "[ 0.00457798  0.78377617 -0.09685316 -1.28366187]\n",
      "[ 0.0202535   0.59001169 -0.1225264  -1.02280763]\n",
      "[ 0.03205373  0.39671594 -0.14298255 -0.77097041]\n",
      "[ 0.03998805  0.59348566 -0.15840196 -1.10500683]\n",
      "[ 0.05185777  0.40076059 -0.1805021  -0.86591409]\n",
      "[ 0.05987298  0.59781931 -0.19782038 -1.20947988]\n",
      "Episode finished after 20 timesteps\n",
      "[-0.00070855 -0.00736491 -0.00861814 -0.0148657 ]\n",
      "[-0.00085585  0.18787957 -0.00891546 -0.31025525]\n",
      "[ 0.00290174  0.3831274  -0.01512056 -0.60573647]\n",
      "[ 0.01056429  0.57845749 -0.02723529 -0.90314339]\n",
      "[ 0.02213344  0.38371484 -0.04529816 -0.61914393]\n",
      "[ 0.02980774  0.18925388 -0.05768104 -0.34106481]\n",
      "[ 0.03359282 -0.00500198 -0.06450234 -0.06711444]\n",
      "[ 0.03349278 -0.1991427  -0.06584462  0.20454051]\n",
      "[ 0.02950992 -0.39326426 -0.06175381  0.47574753]\n",
      "[ 0.02164464 -0.58746233 -0.05223886  0.74834529]\n",
      "[ 0.00989539 -0.39166015 -0.03727196  0.43969143]\n",
      "[ 0.00206219 -0.58623532 -0.02847813  0.72039606]\n",
      "[-0.00966252 -0.39073119 -0.01407021  0.41888733]\n",
      "[-0.01747714 -0.19541271 -0.00569246  0.12180212]\n",
      "[-0.0213854  -0.00020967 -0.00325642 -0.17267128]\n",
      "[-0.02138959 -0.19528486 -0.00670984  0.11898258]\n",
      "[-2.52952868e-02 -6.74201498e-05 -4.33019288e-03 -1.75809673e-01]\n",
      "[-0.02529664 -0.19512713 -0.00784639  0.11550408]\n",
      "[-0.02919918 -0.39013578 -0.0055363   0.40570124]\n",
      "[-0.03700189 -0.19493576  0.00257772  0.11127803]\n",
      "[-4.09006089e-02  1.49156276e-04  4.80328068e-03 -1.80590529e-01]\n",
      "[-0.04089763 -0.1950412   0.00119147  0.11360378]\n",
      "[-4.47984497e-02  6.36609257e-05  3.46354578e-03 -1.78703004e-01]\n",
      "[-4.47971765e-02 -1.95107683e-01 -1.10514302e-04  1.15070536e-01]\n",
      "[-0.04869933 -0.39022805  0.0021909   0.40771859]\n",
      "[-0.05650389 -0.585381    0.01034527  0.70109144]\n",
      "[-0.06821151 -0.78064482  0.0243671   0.99701294]\n",
      "[-0.08382441 -0.58585702  0.04430736  0.7120812 ]\n",
      "[-0.09554155 -0.39137567  0.05854898  0.43366759]\n",
      "[-0.10336906 -0.58727557  0.06722233  0.74421748]\n",
      "[-0.11511457 -0.39314258  0.08210668  0.47342418]\n",
      "[-0.12297742 -0.19927036  0.09157516  0.20770779]\n",
      "[-0.12696283 -0.39557433  0.09572932  0.52781545]\n",
      "[-0.13487432 -0.20192039  0.10628563  0.26676596]\n",
      "[-0.13891273 -0.00846322  0.11162095  0.0094069 ]\n",
      "[-0.13908199  0.18489566  0.11180909 -0.246078  ]\n",
      "[-0.13538408 -0.01163086  0.10688753  0.07967449]\n",
      "[-0.13561669  0.18180938  0.10848102 -0.17746479]\n",
      "[-0.13198051 -0.01468431  0.10493172  0.14737408]\n",
      "[-0.13227419 -0.21114019  0.1078792   0.47123041]\n",
      "[-0.136497   -0.01769418  0.11730381  0.21440323]\n",
      "[-0.13685088  0.1755724   0.12159188 -0.03909611]\n",
      "[-0.13333943 -0.02106436  0.12080995  0.28934132]\n",
      "[-0.13376072 -0.21768329  0.12659678  0.61755188]\n",
      "[-0.13811439 -0.02453591  0.13894782  0.36726946]\n",
      "[-0.1386051  -0.22133058  0.14629321  0.70033582]\n",
      "[-0.14303171 -0.41814501  0.16029992  1.03526093]\n",
      "[-0.15139461 -0.61499287  0.18100514  1.37367377]\n",
      "[-0.16369447 -0.81185616  0.20847862  1.71706995]\n",
      "Episode finished after 49 timesteps\n",
      "[-0.04917956  0.02795917 -0.0114937   0.0466415 ]\n",
      "[-0.04862038  0.22324403 -0.01056087 -0.24964551]\n",
      "[-0.0441555   0.02827447 -0.01555378  0.03968767]\n",
      "[-0.04359001  0.22361597 -0.01476002 -0.25786176]\n",
      "[-0.03911769  0.02870782 -0.01991726  0.03012933]\n",
      "[-0.03854354 -0.16612293 -0.01931467  0.3164622 ]\n",
      "[-0.04186599 -0.36096452 -0.01298543  0.60299191]\n",
      "[-0.04908528 -0.55590246 -0.00092559  0.89155657]\n",
      "[-0.06020333 -0.75101184  0.01690554  1.18394839]\n",
      "[-0.07522357 -0.94634899  0.04058451  1.48188224]\n",
      "[-0.09415055 -0.75174496  0.07022215  1.20214513]\n",
      "[-0.10918545 -0.94770118  0.09426506  1.51598339]\n",
      "[-0.12813947 -1.14382885  0.12458472  1.83654168]\n",
      "[-0.15101605 -1.34008845  0.16131556  2.16518261]\n",
      "[-0.17781782 -1.53637884  0.20461921  2.50301684]\n",
      "Episode finished after 15 timesteps\n",
      "[ 0.03235358  0.01081716 -0.00207782 -0.01875895]\n",
      "[ 0.03256992  0.20596885 -0.002453   -0.31209673]\n",
      "[ 0.0366893   0.01088193 -0.00869494 -0.02018842]\n",
      "[ 0.03690694  0.20612749 -0.00909871 -0.31560197]\n",
      "[ 0.04102949  0.01113632 -0.01541075 -0.0258023 ]\n",
      "[ 0.04125222 -0.18376128 -0.01592679  0.2619788 ]\n",
      "[ 0.03757699 -0.3786523  -0.01068722  0.54959599]\n",
      "[ 0.03000394 -0.18338187  0.0003047   0.25356509]\n",
      "[ 0.02633631 -0.37850818  0.00537601  0.54634411]\n",
      "[ 0.01876614 -0.57370525  0.01630289  0.84071602]\n",
      "[ 0.00729204 -0.76904592  0.03311721  1.13848094]\n",
      "[-0.00808888 -0.57437232  0.05588683  0.85636533]\n",
      "[-0.01957633 -0.3800546   0.07301413  0.58176599]\n",
      "[-0.02717742 -0.18602752  0.08464945  0.3129479 ]\n",
      "[-0.03089797  0.00779292  0.09090841  0.04811546]\n",
      "[-0.03074211  0.20150167  0.09187072 -0.21455756]\n",
      "[-0.02671208  0.3951983   0.08757957 -0.47690522]\n",
      "[-0.01880811  0.58898157  0.07804147 -0.74075059]\n",
      "[-0.00702848  0.78294431  0.06322645 -1.00788823]\n",
      "[ 0.00863041  0.9771678   0.04306869 -1.28006515]\n",
      "[ 0.02817376  1.17171528  0.01746739 -1.55895749]\n",
      "[ 0.05160807  1.36662384 -0.01371176 -1.84614058]\n",
      "[ 0.07894055  1.1716556  -0.05063458 -1.55774684]\n",
      "[ 0.10237366  1.36734599 -0.08178951 -1.86578641]\n",
      "[ 0.12972058  1.56326254 -0.11910524 -2.18269817]\n",
      "[ 0.16098583  1.75932169 -0.1627592  -2.50963758]\n",
      "Episode finished after 26 timesteps\n",
      "[-0.0465621   0.0278468  -0.03602098 -0.00557327]\n",
      "[-0.04600516  0.22346633 -0.03613244 -0.30940011]\n",
      "[-0.04153583  0.02887733 -0.04232044 -0.02832774]\n",
      "[-0.04095829 -0.16561297 -0.042887    0.250708  ]\n",
      "[-0.04427055 -0.36009709 -0.03787284  0.52956101]\n",
      "[-0.05147249 -0.55466635 -0.02728162  0.81007367]\n",
      "[-0.06256582 -0.35918145 -0.01108015  0.50893563]\n",
      "[-0.06974945 -0.55414555 -0.00090143  0.79810634]\n",
      "[-0.08083236 -0.35901125  0.01506069  0.50513997]\n",
      "[-0.08801258 -0.16410474  0.02516349  0.21724105]\n",
      "[-0.09129468  0.03064862  0.02950831 -0.06739922]\n",
      "[-0.0906817  -0.16488369  0.02816033  0.23444575]\n",
      "[-0.09397938  0.02982483  0.03284924 -0.04922319]\n",
      "[-0.09338288 -0.16575238  0.03186478  0.25364029]\n",
      "[-0.09669793  0.02890044  0.03693759 -0.02882405]\n",
      "[-0.09611992  0.22347374  0.03636111 -0.30962775]\n",
      "[-0.09165044  0.41805927  0.03016855 -0.5906253 ]\n",
      "[-0.08328926  0.2225282   0.01835604 -0.28859395]\n",
      "[-0.0788387   0.02714936  0.01258417  0.00982131]\n",
      "[-0.07829571 -0.16815078  0.01278059  0.30644797]\n",
      "[-0.08165872 -0.3634525   0.01890955  0.60313402]\n",
      "[-0.08892777 -0.16860006  0.03097223  0.31646669]\n",
      "[-0.09229977 -0.36414917  0.03730157  0.61875405]\n",
      "[-0.09958276 -0.16956755  0.04967665  0.33804878]\n",
      "[-0.10297411 -0.3653599   0.05643762  0.64597394]\n",
      "[-0.11028131 -0.1710679   0.0693571   0.37158381]\n",
      "[-0.11370267  0.02300369  0.07678878  0.10155096]\n",
      "[-0.11324259  0.21694596  0.0788198  -0.16595146]\n",
      "[-0.10890367  0.41085634  0.07550077 -0.43276496]\n",
      "[-0.10068655  0.60483264  0.06684547 -0.70072436]\n",
      "[-0.08858989  0.40885086  0.05283098 -0.38777029]\n",
      "[-0.08041288  0.60318464  0.04507557 -0.66333917]\n",
      "[-0.06834918  0.79765147  0.03180879 -0.94149539]\n",
      "[-0.05239615  0.60211562  0.01297888 -0.63898977]\n",
      "[-4.03538409e-02  4.06815129e-01  1.99088307e-04 -3.42248027e-01]\n",
      "[-0.03221754  0.21169035 -0.00664587 -0.04950233]\n",
      "[-0.02798373  0.01666432 -0.00763592  0.24107638]\n",
      "[-0.02765045 -0.17834773 -0.00281439  0.53134099]\n",
      "[-0.0312174  -0.37342998  0.00781243  0.82313577]\n",
      "[-0.038686   -0.17841577  0.02427514  0.53292022]\n",
      "[-0.04225431  0.0163565   0.03493355  0.24798408]\n",
      "[-0.04192718  0.21096259  0.03989323 -0.03347858]\n",
      "[-0.03770793  0.01529194  0.03922366  0.27151938]\n",
      "[-0.03740209 -0.18036713  0.04465405  0.57631104]\n",
      "[-0.04100944  0.01410138  0.05618027  0.29802298]\n",
      "[-0.04072741 -0.18177453  0.06214073  0.60788161]\n",
      "[-0.0443629  -0.3777077   0.07429836  0.91947172]\n",
      "[-0.05191705 -0.57375102  0.09268779  1.23454904]\n",
      "[-0.06339207 -0.76993405  0.11737877  1.55477165]\n",
      "[-0.07879076 -0.57639809  0.14847421  1.30089546]\n",
      "[-0.09031872 -0.38343905  0.17449212  1.05813253]\n",
      "[-0.0979875  -0.58038901  0.19565477  1.40011213]\n",
      "Episode finished after 52 timesteps\n",
      "[ 0.02155443  0.0120632  -0.00335628  0.00782831]\n",
      "[ 0.0217957   0.20723313 -0.00319971 -0.28591167]\n",
      "[ 0.02594036  0.40240056 -0.00891795 -0.57960204]\n",
      "[ 0.03398837  0.20740472 -0.02050999 -0.28974174]\n",
      "[ 0.03813647  0.01258114 -0.02630482 -0.00359735]\n",
      "[ 0.03838809  0.20807027 -0.02637677 -0.30446233]\n",
      "[ 0.04254949  0.40355799 -0.03246602 -0.60534579]\n",
      "[ 0.05062065  0.59911855 -0.04457293 -0.90807536]\n",
      "[ 0.06260302  0.4046274  -0.06273444 -0.6297285 ]\n",
      "[ 0.07069557  0.60056609 -0.07532901 -0.9414902 ]\n",
      "[ 0.08270689  0.79661796 -0.09415881 -1.25685982]\n",
      "[ 0.09863925  0.60281886 -0.11929601 -0.99509069]\n",
      "[ 0.11069563  0.79931688 -0.13919782 -1.32273275]\n",
      "[ 0.12668197  0.60620074 -0.16565248 -1.0766525 ]\n",
      "[ 0.13880598  0.41360796 -0.18718553 -0.84019733]\n",
      "[ 0.14707814  0.6107245  -0.20398948 -1.18541899]\n",
      "Episode finished after 16 timesteps\n",
      "[-0.01571941  0.00381205  0.02120125  0.03930446]\n",
      "[-0.01564317  0.19862366  0.02198734 -0.24661458]\n",
      "[-0.01167069  0.3934248   0.01705505 -0.53228191]\n",
      "[-0.0038022   0.19806717  0.00640941 -0.23427414]\n",
      "[0.00015915 0.00285423 0.00172392 0.0604236 ]\n",
      "[ 2.16229873e-04 -1.92292394e-01  2.93239661e-03  3.53649942e-01]\n",
      "[-0.00362962  0.00278774  0.0100054   0.06189313]\n",
      "[-0.00357386  0.19776482  0.01124326 -0.22761631]\n",
      "[0.00038143 0.00248401 0.00669093 0.06859183]\n",
      "[ 0.00043111 -0.19273323  0.00806277  0.36337825]\n",
      "[-0.00342355  0.00227321  0.01533033  0.07324853]\n",
      "[-0.00337809 -0.19306513  0.0167953   0.37072855]\n",
      "[-0.00723939 -0.38842162  0.02420987  0.66865954]\n",
      "[-0.01500782 -0.5838717   0.03758307  0.96886576]\n",
      "[-0.02668526 -0.77947752  0.05696038  1.27311412]\n",
      "[-0.04227481 -0.97527815  0.08242266  1.58307603]\n",
      "[-0.06178037 -0.78122786  0.11408418  1.31719358]\n",
      "[-0.07740493 -0.58771868  0.14042806  1.06228473]\n",
      "[-0.0891593  -0.39470688  0.16167375  0.81676728]\n",
      "[-0.09705344 -0.20212374  0.1780091   0.578985  ]\n",
      "[-0.10109591 -0.39923489  0.1895888   0.92203837]\n",
      "[-0.10908061 -0.59634261  0.20802956  1.26780802]\n",
      "Episode finished after 22 timesteps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        plt.imshow(env.render(mode='rgb_array'))\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
